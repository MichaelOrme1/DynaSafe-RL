This is the repository for DynaSafe-RL, a dynamic unlearning framework that enables real-time behavioural regulation of large language models without retraining or parameter access.

This repository is structured as follows:

Testing Code - all of the code for running models and carrying out tests. Requires Gemini API KEY.

RL Models - the models that select each strategy, required for using DynaSafe-RL.

Comparison Code - creates visualisations and statistical tests of all of the methods.

Results - full results obtained over the course of our experiments, required by the code in Comparison Code.

Supplementary Material - contains reports detailing static methods and the Deep Eval Metrics used for the prompt rating.

Prompts - contains the unsafe prompts used for testing the models, required for model use.



